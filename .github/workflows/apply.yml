name: Terragrunt Apply

on:
  push:
    branches:
      - main

concurrency:
  group: terragrunt-apply-${{ github.ref }}
  cancel-in-progress: false

env:
  TF_VAR_WEBHOOK_PATH: ${{ secrets.WEBHOOK_PATH }}
  TF_VAR_github_token: ${{ secrets.TF_VAR_github_token }}
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  TERRAGRUNT_VERSION: 0.67.16
  TERRAFORM_VERSION: 1.9.8

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  check-changes:
    name: Check for Changes and Labels
    runs-on: ubuntu-latest
    outputs:
      changes: ${{ steps.changes.outputs.changes }}
      keeping_changes: ${{ steps.changes.outputs.keeping_changes }}
      scheduling_changes: ${{ steps.changes.outputs.scheduling_changes }}
      pr_number: ${{ steps.pr_search.outputs.pr_number }}
      labels: ${{ steps.pr_labels.outputs.labels }}
      should_run_keeping: ${{ steps.check_targets.outputs.should_run_keeping }}
      should_run_scheduling: ${{ steps.check_targets.outputs.should_run_scheduling }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Find PR associated with the commit
        id: pr_search
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "=== Finding PR number from merge commit ==="
          
          # Get the latest commit message
          COMMIT_MSG="$(git log -1 --pretty=format:%B)"
          echo "Latest commit message:"
          echo "$COMMIT_MSG"
          
          # Extract PR number from merge commit message
          PR_NUMBER="$(echo "$COMMIT_MSG" | grep -o 'Merge pull request #[0-9]\+' | grep -o '[0-9]\+' | head -1)"
          
          if [ -n "$PR_NUMBER" ] && [ "$PR_NUMBER" != "" ]; then
            echo "✅ Found PR number: $PR_NUMBER"
            echo "pr_number=$PR_NUMBER" >> "$GITHUB_OUTPUT"
          else
            echo "⚠️ No PR number found in commit message"
            echo "Commit message: $COMMIT_MSG"
            
            # Alternative: try to find PR from commit SHA using GitHub API
            echo "Trying alternative method with GitHub API..."
            COMMIT_SHA="${{ github.sha }}"
            echo "Current commit SHA: $COMMIT_SHA"
            
            # Try to get PR from commit SHA
            if API_PR_NUMBER=$(gh api "repos/${{ github.repository }}/commits/$COMMIT_SHA/pulls" --jq '.[0].number' 2>/dev/null); then
              if [ -n "$API_PR_NUMBER" ] && [ "$API_PR_NUMBER" != "null" ]; then
                echo "✅ Found PR number via API: $API_PR_NUMBER"
                echo "pr_number=$API_PR_NUMBER" >> "$GITHUB_OUTPUT"
              else
                echo "⚠️ No PR found via API"
                echo "pr_number=" >> "$GITHUB_OUTPUT"
              fi
            else
              echo "❌ Failed to query GitHub API"
              echo "pr_number=" >> "$GITHUB_OUTPUT"
            fi
          fi
          
      - name: Get PR labels
        id: pr_labels
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          PR_NUMBER=${{ steps.pr_search.outputs.pr_number }}
          echo "=== Getting labels for PR #$PR_NUMBER ==="
          
          if [ -n "$PR_NUMBER" ] && [ "$PR_NUMBER" != "" ]; then
            echo "Fetching labels for PR #$PR_NUMBER..."
            
            # Try to get PR labels
            if LABELS="$(gh pr view $PR_NUMBER --json labels --jq '.labels[].name' 2>/dev/null | tr '\n' ' ')"; then
              echo "✅ Successfully retrieved labels: $LABELS"
              echo "labels=$LABELS" >> "$GITHUB_OUTPUT"
            else
              echo "❌ Failed to get labels for PR #$PR_NUMBER"
              echo "Trying to get PR info..."
              gh pr view $PR_NUMBER --json labels,title,state || echo "PR not found or accessible"
              echo "labels=" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "⚠️ No PR number available, cannot fetch labels"
            echo "labels=" >> "$GITHUB_OUTPUT"
          fi

      - name: Check for relevant changes
        id: changes
        run: |
          # Check for general changes
          DIFF=$(git diff --name-only HEAD^ terragrunt/ terraform/modules terraform/keeping terraform/scheduling)
          
          # Check for keeping-specific changes
          KEEPING_DIFF=$(git diff --name-only HEAD^ terragrunt/environments/keeping/ terraform/keeping/ terraform/modules/)
          
          # Check for scheduling-specific changes
          SCHEDULING_DIFF=$(git diff --name-only HEAD^ terragrunt/environments/scheduling/ terraform/scheduling/ terraform/modules/)
          
          if [[ -n "${DIFF}" ]]; then
            echo "changes=true" >> "$GITHUB_OUTPUT"
            echo "Changed files: ${DIFF}"
          else
            echo "changes=false" >> "$GITHUB_OUTPUT"
            echo "No relevant changes detected"
          fi
          
          if [[ -n "${KEEPING_DIFF}" ]]; then
            echo "keeping_changes=true" >> "$GITHUB_OUTPUT"
            echo "Keeping changes: ${KEEPING_DIFF}"
          else
            echo "keeping_changes=false" >> "$GITHUB_OUTPUT"
            echo "No keeping-specific changes detected"
          fi
          
          if [[ -n "${SCHEDULING_DIFF}" ]]; then
            echo "scheduling_changes=true" >> "$GITHUB_OUTPUT"
            echo "Scheduling changes: ${SCHEDULING_DIFF}"
          else
            echo "scheduling_changes=false" >> "$GITHUB_OUTPUT"
            echo "No scheduling-specific changes detected"
          fi

      - name: Check Target Labels
        id: check_targets
        run: |
          LABELS="${{ steps.pr_labels.outputs.labels }}"
          KEEPING_CHANGES="${{ steps.changes.outputs.keeping_changes }}"
          SCHEDULING_CHANGES="${{ steps.changes.outputs.scheduling_changes }}"
          
          echo "Debug information:"
          echo "Labels: '${LABELS}'"
          echo "Keeping changes: '${KEEPING_CHANGES}'"
          echo "Scheduling changes: '${SCHEDULING_CHANGES}'"
          
          # Check if apply-target-checker.js exists
          if [ -f "./scripts/github-actions/apply-target-checker.js" ]; then
            echo "✅ apply-target-checker.js file exists"
          else
            echo "❌ apply-target-checker.js file NOT found"
            ls -la ./scripts/github-actions/
          fi
          
          # Convert space-separated labels to JavaScript array
          node -e "
          try {
            const applyTargetChecker = require('./scripts/github-actions/apply-target-checker.js');
            const fs = require('fs');
            
            const labels = '$LABELS'.split(' ').filter(l => l);
            const keepingChanges = '$KEEPING_CHANGES' === 'true';
            const schedulingChanges = '$SCHEDULING_CHANGES' === 'true';
            
            console.log('Input to applyTargetChecker:');
            console.log('- labels:', labels);
            console.log('- keepingChanges:', keepingChanges);
            console.log('- schedulingChanges:', schedulingChanges);
            
            const result = applyTargetChecker(labels, keepingChanges, schedulingChanges);
            
            console.log('Result from applyTargetChecker:');
            console.log('- should_run_keeping:', result.should_run_keeping);
            console.log('- should_run_scheduling:', result.should_run_scheduling);
            
            // Write outputs to GITHUB_OUTPUT
            fs.appendFileSync(process.env.GITHUB_OUTPUT, 
              \`should_run_keeping=\${result.should_run_keeping}\\n\`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, 
              \`should_run_scheduling=\${result.should_run_scheduling}\\n\`);
              
            console.log('✅ Successfully wrote outputs to GITHUB_OUTPUT');
            console.log('Final outputs:');
            console.log('- should_run_keeping=' + result.should_run_keeping);
            console.log('- should_run_scheduling=' + result.should_run_scheduling);
          } catch (error) {
            console.error('❌ Error in Node.js script:', error);
            process.exit(1);
          }
          "

      - name: Debug Final Outputs
        run: |
          echo "=== Final Check Changes Debug ==="
          echo "All outputs from this job:"
          echo "  changes: '${{ steps.changes.outputs.changes }}'"
          echo "  keeping_changes: '${{ steps.changes.outputs.keeping_changes }}'"
          echo "  scheduling_changes: '${{ steps.changes.outputs.scheduling_changes }}'"
          echo "  pr_number: '${{ steps.pr_search.outputs.pr_number }}'"
          echo "  labels: '${{ steps.pr_labels.outputs.labels }}'"
          echo "  should_run_keeping: '${{ steps.check_targets.outputs.should_run_keeping }}'"
          echo "  should_run_scheduling: '${{ steps.check_targets.outputs.should_run_scheduling }}'"
          echo ""
          echo "Expected workflow behavior:"
          if [ "${{ steps.check_targets.outputs.should_run_keeping }}" = "true" ]; then
            echo "  ✅ apply-keeping job SHOULD run"
          else
            echo "  ❌ apply-keeping job should NOT run"
          fi
          if [ "${{ steps.check_targets.outputs.should_run_scheduling }}" = "true" ]; then
            echo "  ✅ apply-scheduling job SHOULD run"
          else
            echo "  ❌ apply-scheduling job should NOT run"
          fi

  debug-conditions:
    name: Debug Job Conditions
    runs-on: ubuntu-latest
    needs: [check-changes]
    steps:
      - name: Debug All Conditions
        run: |
          echo "=== Debugging ALL job conditions ==="
          echo ""
          echo "=== check-changes outputs ==="
          echo "  changes: '${{ needs.check-changes.outputs.changes }}'"
          echo "  keeping_changes: '${{ needs.check-changes.outputs.keeping_changes }}'"
          echo "  scheduling_changes: '${{ needs.check-changes.outputs.scheduling_changes }}'"
          echo "  pr_number: '${{ needs.check-changes.outputs.pr_number }}'"
          echo "  labels: '${{ needs.check-changes.outputs.labels }}'"
          echo "  should_run_keeping: '${{ needs.check-changes.outputs.should_run_keeping }}'"
          echo "  should_run_scheduling: '${{ needs.check-changes.outputs.should_run_scheduling }}'"
          echo ""
          echo "=== apply-keeping job condition evaluation ==="
          echo "  should_run_keeping value: '${{ needs.check-changes.outputs.should_run_keeping }}'"
          echo "  should_run_keeping == 'true': ${{ needs.check-changes.outputs.should_run_keeping == 'true' }}"
          echo "  Type of should_run_keeping: ${{ type(needs.check-changes.outputs.should_run_keeping) }}"
          echo ""
          echo "=== apply-scheduling job condition evaluation ==="
          echo "  should_run_scheduling value: '${{ needs.check-changes.outputs.should_run_scheduling }}'"
          echo "  should_run_scheduling == 'true': ${{ needs.check-changes.outputs.should_run_scheduling == 'true' }}"
          echo "  Type of should_run_scheduling: ${{ type(needs.check-changes.outputs.should_run_scheduling) }}"
          echo ""
          echo "=== GitHub Actions context debug ==="
          echo "  github.event_name: ${{ github.event_name }}"
          echo "  github.ref: ${{ github.ref }}"
          echo "  github.sha: ${{ github.sha }}"
          echo "  github.workflow: ${{ github.workflow }}"
          echo ""
          echo "=== Condition results ==="
          if [[ "${{ needs.check-changes.outputs.should_run_keeping }}" == "true" ]]; then
            echo "  ✅ apply-keeping should run (bash evaluation)"
          else
            echo "  ❌ apply-keeping should NOT run (bash evaluation)"
            echo "  Value was: '${{ needs.check-changes.outputs.should_run_keeping }}'"
          fi
          
          if [[ "${{ needs.check-changes.outputs.should_run_scheduling }}" == "true" ]]; then
            echo "  ✅ apply-scheduling should run (bash evaluation)"
          else
            echo "  ❌ apply-scheduling should NOT run (bash evaluation)"
            echo "  Value was: '${{ needs.check-changes.outputs.should_run_scheduling }}'"
          fi
          echo ""
          echo "=== Final job condition tests ==="
          echo "Testing apply-keeping condition: always() && needs.check-changes.outputs.should_run_keeping == 'true'"
          echo "  always(): true (always evaluates to true)"
          echo "  should_run_keeping == 'true': ${{ needs.check-changes.outputs.should_run_keeping == 'true' }}"
          echo "  Final result: Expected to be same as should_run_keeping == 'true'"
          echo ""
          echo "Testing apply-scheduling condition: needs.check-changes.outputs.should_run_scheduling == 'true' && always()"
          echo "  should_run_scheduling == 'true': ${{ needs.check-changes.outputs.should_run_scheduling == 'true' }}"
          echo "  always(): true (always evaluates to true)"  
          echo "  Final result: Expected to be same as should_run_scheduling == 'true'"

  apply-keeping:
    name: Terragrunt Apply - Keeping
    runs-on: ubuntu-latest
    needs: [check-changes, debug-conditions]
    if: always() && needs.check-changes.outputs.should_run_keeping == 'true'
    outputs:
      apply_status: ${{ steps.apply.outputs.status }}
      resources_applied: ${{ steps.apply.outputs.resources_applied }}
      resources_changed: ${{ steps.apply.outputs.resources_changed }}
      resources_destroyed: ${{ steps.apply.outputs.resources_destroyed }}
    steps:
      - name: Debug Job Conditions
        run: |
          echo "=== Debugging apply-keeping job conditions ==="
          echo "should_run_keeping output: '${{ needs.check-changes.outputs.should_run_keeping }}'"
          echo "Type check: '${{ needs.check-changes.outputs.should_run_keeping }}' == 'true'"
          echo "Condition result: ${{ needs.check-changes.outputs.should_run_keeping == 'true' }}"
          echo "All check-changes outputs:"
          echo "  changes: '${{ needs.check-changes.outputs.changes }}'"
          echo "  keeping_changes: '${{ needs.check-changes.outputs.keeping_changes }}'"
          echo "  scheduling_changes: '${{ needs.check-changes.outputs.scheduling_changes }}'"
          echo "  pr_number: '${{ needs.check-changes.outputs.pr_number }}'"
          echo "  labels: '${{ needs.check-changes.outputs.labels }}'"
          echo "  should_run_keeping: '${{ needs.check-changes.outputs.should_run_keeping }}'"
          echo "  should_run_scheduling: '${{ needs.check-changes.outputs.should_run_scheduling }}'"
          
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/minecraft-test-github-actions
          role-session-name: github-actions-apply-keeping-session
          aws-region: ap-northeast-1

      - name: Setup aqua
        uses: aquaproj/aqua-installer@v4.0.2
        with:
          aqua_version: v2.30.0

      - name: Install tools via aqua
        run: aqua install --all

      - name: Setup Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Verify Python Installation
        run: |
          echo "Python version: $(python3 --version)"
          echo "Python executable path: $(which python3)"
          echo "Lambda packaging will use this Python interpreter"

      - name: Check if keeping environment exists
        id: check-env
        run: |
          echo "=== Debugging keeping environment check ==="
          echo "Current working directory: $(pwd)"
          echo "Listing current directory:"
          ls -la
          echo ""
          echo "Looking for terragrunt directory:"
          ls -la terragrunt/ || echo "terragrunt directory not found"
          echo ""
          echo "Looking for terragrunt/environments:"
          ls -la terragrunt/environments/ || echo "terragrunt/environments directory not found"
          echo ""
          echo "Looking for terragrunt/environments/keeping:"
          ls -la terragrunt/environments/keeping/ || echo "terragrunt/environments/keeping directory not found"
          echo ""
          
          if [ -d "terragrunt/environments/keeping" ]; then
            echo "✅ terragrunt/environments/keeping exists"
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "❌ terragrunt/environments/keeping does not exist"
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Terragrunt Apply - Keeping
        id: apply
        if: steps.check-env.outputs.exists == 'true'
        working-directory: terragrunt/environments/keeping
        run: |
          # Function to handle state lock issues
          handle_state_lock() {
            local max_retries=3
            local retry_count=0
            
            while [ "$retry_count" -lt "$max_retries" ]; do
              echo "=== Keeping Environment - Attempt $((retry_count + 1))/$max_retries ==="
              
              # Initialize first
              init_exit_code=0
              terragrunt init --terragrunt-non-interactive 2>&1 | tee init_output.txt || init_exit_code=$?
              
              if [ "$init_exit_code" -ne 0 ]; then
                echo "❌ Keeping init failed on attempt $((retry_count + 1))"
                echo "=== Keeping Init Error Details ==="
                tail -20 init_output.txt
                echo "=== End Keeping Init Error Details ==="
                
                if [ "$retry_count" -eq $((max_retries - 1)) ]; then
                  echo "status=init_failed" >> "$GITHUB_OUTPUT"
                  echo "resources_applied=0" >> "$GITHUB_OUTPUT"
                  echo "resources_changed=0" >> "$GITHUB_OUTPUT"
                  echo "resources_destroyed=0" >> "$GITHUB_OUTPUT"
                  # Preserve init error details for debugging
                  cp init_output.txt apply_errors.txt
                  return 1
                fi
                retry_count=$((retry_count + 1))
                echo "⏳ Waiting 30 seconds before retry..."
                sleep 30
                continue
              fi
              
              # Run plan first to validate the configuration
              plan_exit_code=0
              terragrunt plan --terragrunt-non-interactive -out=tfplan > plan_output.txt 2>&1 || plan_exit_code=$?
              
              if [ "$plan_exit_code" -ne 0 ]; then
                echo "❌ Keeping plan failed on attempt $((retry_count + 1))"
                echo "=== Keeping Plan Error Details ==="
                tail -30 plan_output.txt
                echo "=== End Keeping Plan Error Details ==="
                
                # Check for common dependency errors
                if grep -q "no matching.*found" plan_output.txt; then
                  echo "🔍 Detected missing resource dependency in keeping environment"
                fi
                if grep -q "couldn't find resource" plan_output.txt; then
                  echo "🔍 Detected missing AWS resource in keeping environment"
                fi
                
                # Capture plan errors for better debugging
                cp plan_output.txt plan_errors.txt
                
                if [ "$retry_count" -eq $((max_retries - 1)) ]; then
                  echo "status=plan_failed" >> "$GITHUB_OUTPUT"
                  echo "resources_applied=0" >> "$GITHUB_OUTPUT"
                  echo "resources_changed=0" >> "$GITHUB_OUTPUT"
                  echo "resources_destroyed=0" >> "$GITHUB_OUTPUT"
                  # Ensure error details are preserved for debugging
                  cp plan_output.txt apply_errors.txt
                  return 1
                fi
                retry_count=$((retry_count + 1))
                echo "⏳ Waiting 30 seconds before retry..."
                sleep 30
                continue
              fi
              
              echo "✅ Keeping plan completed successfully, proceeding with apply"
              
              # Run apply with auto-approve using the saved plan
              apply_exit_code=0
              terragrunt apply --terragrunt-non-interactive -auto-approve tfplan > apply_output.txt 2>&1 || apply_exit_code=$?
              
              # Check if this was a lock error
              if [ "$apply_exit_code" -ne 0 ] && grep -q "Error acquiring the state lock" apply_output.txt; then
                echo "⚠️ Keeping state lock error detected on attempt $((retry_count + 1))"
                if [ "$retry_count" -eq $((max_retries - 1)) ]; then
                  echo "❌ Max retries reached, failing..."
                  break
                fi
                retry_count=$((retry_count + 1))
                echo "⏳ Waiting 60 seconds for lock to be released..."
                sleep 60
                continue
              else
                # Either success or non-lock error, break the loop
                break
              fi
            done
            
            return "$apply_exit_code"
          }
          
          # Execute with retry logic
          handle_state_lock
          final_exit_code=$?
          
          # Create empty error file for consistency
          touch apply_errors.txt
          
          # Parse results and set resource counts
          if [ -f "apply_output.txt" ]; then
            # Count different types of operations from apply output
            created=$(grep -c "Creation complete after" apply_output.txt 2>/dev/null) || created=0
            modified=$(grep -c "Modifications complete after" apply_output.txt 2>/dev/null) || modified=0
            destroyed=$(grep -c "Destruction complete after" apply_output.txt 2>/dev/null) || destroyed=0
            
            # Also try to parse from apply summary if available
            apply_add=$(grep -o "[0-9]\+ added" apply_output.txt | grep -o "[0-9]\+" | head -1) || apply_add=0
            apply_changed=$(grep -o "[0-9]\+ changed" apply_output.txt | grep -o "[0-9]\+" | head -1) || apply_changed=0
            apply_destroyed=$(grep -o "[0-9]\+ destroyed" apply_output.txt | grep -o "[0-9]\+" | head -1) || apply_destroyed=0
            
            # Use whichever count is higher
            resources_applied=$((created > apply_add ? created : apply_add))
            resources_changed=$((modified > apply_changed ? modified : apply_changed))
            resources_destroyed=$((destroyed > apply_destroyed ? destroyed : apply_destroyed))
            
            echo "resources_applied=$resources_applied" >> "$GITHUB_OUTPUT"
            echo "resources_changed=$resources_changed" >> "$GITHUB_OUTPUT"
            echo "resources_destroyed=$resources_destroyed" >> "$GITHUB_OUTPUT"
          else
            echo "resources_applied=0" >> "$GITHUB_OUTPUT"
            echo "resources_changed=0" >> "$GITHUB_OUTPUT"
            echo "resources_destroyed=0" >> "$GITHUB_OUTPUT"
          fi
          
          # Determine status based on apply result
          apply_status="unknown"
          
          if [ "$final_exit_code" -eq 0 ]; then
            if [ -f "apply_output.txt" ] && (grep -q "Apply complete!" apply_output.txt || grep -q "No changes" apply_output.txt); then
              apply_status="success"
              echo "✅ Keeping apply completed successfully"
            else
              apply_status="completed_with_warnings"
              echo "⚠️ Keeping apply completed but with potential warnings"
            fi
          else
            apply_status="failed"
            echo "❌ Keeping apply failed: Exit code $final_exit_code"
            
            # Enhanced error capture for better debugging
            echo "=== Capturing error details for debugging ==="
            if [ -f "apply_output.txt" ] && [ -s "apply_output.txt" ]; then
              echo "Using apply output for error details"
              tail -50 apply_output.txt > apply_errors.txt
            elif [ -f "plan_errors.txt" ] && [ -s "plan_errors.txt" ]; then
              echo "Using plan errors for error details" 
              cp plan_errors.txt apply_errors.txt
            elif [ -f "plan_output.txt" ] && [ -s "plan_output.txt" ]; then
              echo "Using plan output for error details"
              tail -50 plan_output.txt > apply_errors.txt
            elif [ -f "init_output.txt" ] && [ -s "init_output.txt" ]; then
              echo "Using init output for error details"
              tail -50 init_output.txt > apply_errors.txt
            else
              echo "No detailed error logs available" > apply_errors.txt
            fi
            
            exit 1
          fi
          
          # Set the status output
          echo "status=$apply_status" >> "$GITHUB_OUTPUT"
        env:
          TF_VAR_aws_account_id: ${{ env.AWS_ACCOUNT_ID }}

      - name: Debug Apply Results for Keeping
        if: always() && steps.check-env.outputs.exists == 'true'
        working-directory: terragrunt/environments/keeping
        run: |
          echo "=== Debugging Apply Results for Keeping ==="
          echo "Checking for apply output files..."
          
          if [ -f "apply_output.txt" ]; then
            echo "✅ apply_output.txt exists, size: $(wc -c < apply_output.txt) bytes"
            echo "=== Full Apply Output ==="
            cat apply_output.txt
            echo "=== End Full Apply Output ==="
          else
            echo "❌ apply_output.txt not found"
          fi
          
          if [ -f "plan_output.txt" ]; then
            echo "✅ plan_output.txt exists, size: $(wc -c < plan_output.txt) bytes"
            echo "=== Plan Output ==="
            cat plan_output.txt
            echo "=== End Plan Output ==="
          else
            echo "❌ plan_output.txt not found"
          fi
          
          if [ -f "init_output.txt" ]; then
            echo "✅ init_output.txt exists, size: $(wc -c < init_output.txt) bytes"
          else
            echo "❌ init_output.txt not found"
          fi
          
          if [ -f "apply_errors.txt" ]; then
            echo "✅ apply_errors.txt exists, size: $(wc -c < apply_errors.txt) bytes"
            if [ -s "apply_errors.txt" ]; then
              echo "=== Apply Errors Content ==="
              cat apply_errors.txt
              echo "=== End Apply Errors ==="
            fi
          else
            echo "❌ apply_errors.txt not found"
          fi

      - name: Upload Keeping Apply Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: terragrunt-apply-keeping
          path: |
            terragrunt/environments/keeping/apply_output.txt
            terragrunt/environments/keeping/plan_output.txt
            terragrunt/environments/keeping/init_output.txt
            terragrunt/environments/keeping/apply_errors.txt
            terragrunt/environments/keeping/plan_errors.txt
          retention-days: 30

      - name: Slack Notification on Success
        if: success()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: https://hooks.slack.com/services/${{ secrets.WEBHOOK_PATH }}
          SLACK_USERNAME: TerragruntBot
          SLACK_TITLE: "Terragrunt Apply Success - keeping"
          SLACK_COLOR: good
          SLACK_MESSAGE: "keeping environment applied successfully 🚀"

      - name: Slack Notification on Failure
        if: failure()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: https://hooks.slack.com/services/${{ secrets.WEBHOOK_PATH }}
          SLACK_USERNAME: TerragruntBot
          SLACK_TITLE: "Terragrunt Apply Failed - keeping"
          SLACK_COLOR: danger
          SLACK_MESSAGE: "keeping environment apply failed 😢"

  apply-scheduling:
    name: Terragrunt Apply - Scheduling
    runs-on: ubuntu-latest
    needs: [check-changes, debug-conditions, apply-keeping]
    if: |
      needs.check-changes.outputs.should_run_scheduling == 'true' && 
      always()
    outputs:
      apply_status: ${{ steps.apply.outputs.status }}
      resources_applied: ${{ steps.apply.outputs.resources_applied }}
      resources_changed: ${{ steps.apply.outputs.resources_changed }}
      resources_destroyed: ${{ steps.apply.outputs.resources_destroyed }}
    steps:
      - name: Debug Job Conditions for Scheduling
        run: |
          echo "=== Debugging apply-scheduling job conditions ==="
          echo "should_run_scheduling output: '${{ needs.check-changes.outputs.should_run_scheduling }}'"
          echo "Type check: '${{ needs.check-changes.outputs.should_run_scheduling }}' == 'true'"
          echo "Condition 1 result: ${{ needs.check-changes.outputs.should_run_scheduling == 'true' }}"
          
          echo "apply-keeping result: '${{ needs.apply-keeping.result }}'"
          echo "apply-keeping.result == 'skipped': ${{ needs.apply-keeping.result == 'skipped' }}"
          echo "apply-keeping.result == 'success': ${{ needs.apply-keeping.result == 'success' }}"
          echo "Condition 2 result: ${{ needs.apply-keeping.result == 'skipped' || needs.apply-keeping.result == 'success' }}"
          
          echo "Overall condition result: ${{ needs.check-changes.outputs.should_run_scheduling == 'true' && (needs.apply-keeping.result == 'skipped' || needs.apply-keeping.result == 'success') }}"
          
          echo "All check-changes outputs:"
          echo "  changes: '${{ needs.check-changes.outputs.changes }}'"
          echo "  keeping_changes: '${{ needs.check-changes.outputs.keeping_changes }}'"
          echo "  scheduling_changes: '${{ needs.check-changes.outputs.scheduling_changes }}'"
          echo "  pr_number: '${{ needs.check-changes.outputs.pr_number }}'"
          echo "  labels: '${{ needs.check-changes.outputs.labels }}'"
          echo "  should_run_keeping: '${{ needs.check-changes.outputs.should_run_keeping }}'"
          echo "  should_run_scheduling: '${{ needs.check-changes.outputs.should_run_scheduling }}'"
          
          echo "All apply-keeping outputs and results:"
          echo "  apply-keeping.result: '${{ needs.apply-keeping.result }}'"
          echo "  apply-keeping.outputs.apply_status: '${{ needs.apply-keeping.outputs.apply_status }}'"
          echo "  apply-keeping.outputs.resources_applied: '${{ needs.apply-keeping.outputs.resources_applied }}'"
          echo "  apply-keeping.outputs.resources_changed: '${{ needs.apply-keeping.outputs.resources_changed }}'"
          echo "  apply-keeping.outputs.resources_destroyed: '${{ needs.apply-keeping.outputs.resources_destroyed }}'"
          
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/minecraft-test-github-actions
          role-session-name: github-actions-apply-scheduling-session
          aws-region: ap-northeast-1

      - name: Setup aqua
        uses: aquaproj/aqua-installer@v4.0.2
        with:
          aqua_version: v2.30.0

      - name: Install tools via aqua
        run: aqua install --all

      - name: Setup Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Verify Python Installation
        run: |
          echo "Python version: $(python3 --version)"
          echo "Python executable path: $(which python3)"
          echo "Lambda packaging will use this Python interpreter"

      - name: Create Mapping Yaml for scheduling
        working-directory: terraform/scheduling
        run: |
          cat << EOF > secrets.yaml
          OPS: ${{ secrets.WHITELIST_PLAYERS }}
          WHITELIST: ${{ secrets.WHITELIST_PLAYERS }}
          WEBHOOK_PATH: ${{ secrets.WEBHOOK_PATH }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          S3_PREFIX_NAME: ${{ secrets.S3_PREFIX_NAME }}
          FILTERING_STRINGS: ${{ secrets.FILTERING_STRINGS }}
          EOF

      - name: Check if scheduling environment exists
        id: check-env
        run: |
          if [ -d "terragrunt/environments/scheduling" ]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Terragrunt Apply - Scheduling
        id: apply
        if: steps.check-env.outputs.exists == 'true'
        working-directory: terragrunt/environments/scheduling
        run: |
          # Function to handle state lock issues
          handle_state_lock() {
            local max_retries=3
            local retry_count=0
            
            while [ "$retry_count" -lt "$max_retries" ]; do
              echo "=== Scheduling Environment - Attempt $((retry_count + 1))/$max_retries ==="
              
              # Initialize first
              init_exit_code=0
              terragrunt init --terragrunt-non-interactive 2>&1 | tee init_output.txt || init_exit_code=$?
              
              if [ "$init_exit_code" -ne 0 ]; then
                echo "❌ Scheduling init failed on attempt $((retry_count + 1))"
                echo "=== Scheduling Init Error Details ==="
                tail -20 init_output.txt
                echo "=== End Scheduling Init Error Details ==="
                
                if [ "$retry_count" -eq $((max_retries - 1)) ]; then
                  echo "status=init_failed" >> "$GITHUB_OUTPUT"
                  echo "resources_applied=0" >> "$GITHUB_OUTPUT"
                  echo "resources_changed=0" >> "$GITHUB_OUTPUT"
                  echo "resources_destroyed=0" >> "$GITHUB_OUTPUT"
                  # Preserve init error details for debugging
                  cp init_output.txt apply_errors.txt
                  return 1
                fi
                retry_count=$((retry_count + 1))
                echo "⏳ Waiting 30 seconds before retry..."
                sleep 30
                continue
              fi
              
              # Run plan first to validate the configuration
              plan_exit_code=0
              terragrunt plan --terragrunt-non-interactive -out=tfplan > plan_output.txt 2>&1 || plan_exit_code=$?
              
              if [ "$plan_exit_code" -ne 0 ]; then
                echo "❌ Scheduling plan failed on attempt $((retry_count + 1))"
                echo "=== Scheduling Plan Error Details ==="
                tail -50 plan_output.txt
                echo "=== End Scheduling Plan Error Details ==="
                
                # Check for common dependency errors
                if grep -q "no matching EC2 Security Group found" plan_output.txt; then
                  echo "🔍 Detected missing Security Group dependency"
                fi
                if grep -q "couldn't find resource" plan_output.txt && grep -q "IAM Role" plan_output.txt; then
                  echo "🔍 Detected missing IAM Role dependency"
                fi
                if grep -q "empty result" plan_output.txt && grep -q "SNS Topic" plan_output.txt; then
                  echo "🔍 Detected missing SNS Topic dependency"
                fi
                
                # Capture plan errors for better debugging
                cp plan_output.txt plan_errors.txt
                
                if [ "$retry_count" -eq $((max_retries - 1)) ]; then
                  echo "status=plan_failed" >> "$GITHUB_OUTPUT"
                  echo "resources_applied=0" >> "$GITHUB_OUTPUT"
                  echo "resources_changed=0" >> "$GITHUB_OUTPUT"
                  echo "resources_destroyed=0" >> "$GITHUB_OUTPUT"
                  # Ensure error details are preserved for debugging
                  cp plan_output.txt apply_errors.txt
                  return 1
                fi
                retry_count=$((retry_count + 1))
                echo "⏳ Waiting 30 seconds before retry..."
                sleep 30
                continue
              fi
              
              echo "✅ Scheduling plan completed successfully, proceeding with apply"
              
              # Run apply with auto-approve using the saved plan
              apply_exit_code=0
              terragrunt apply --terragrunt-non-interactive -auto-approve tfplan > apply_output.txt 2>&1 || apply_exit_code=$?
              
              # Check if this was a lock error
              if [ "$apply_exit_code" -ne 0 ] && grep -q "Error acquiring the state lock" apply_output.txt; then
                echo "⚠️ Scheduling state lock error detected on attempt $((retry_count + 1))"
                if [ "$retry_count" -eq $((max_retries - 1)) ]; then
                  echo "❌ Max retries reached, failing..."
                  break
                fi
                retry_count=$((retry_count + 1))
                echo "⏳ Waiting 60 seconds for lock to be released..."
                sleep 60
                continue
              else
                # Either success or non-lock error, break the loop
                break
              fi
            done
            
            return "$apply_exit_code"
          }
          
          # Execute with retry logic
          handle_state_lock
          final_exit_code=$?
          
          # Create empty error file for consistency
          touch apply_errors.txt
          
          # Parse results and set resource counts
          if [ -f "apply_output.txt" ]; then
            # Count different types of operations from apply output
            created=$(grep -c "Creation complete after" apply_output.txt 2>/dev/null) || created=0
            modified=$(grep -c "Modifications complete after" apply_output.txt 2>/dev/null) || modified=0
            destroyed=$(grep -c "Destruction complete after" apply_output.txt 2>/dev/null) || destroyed=0
            
            # Also try to parse from apply summary if available
            apply_add=$(grep -o "[0-9]\+ added" apply_output.txt | grep -o "[0-9]\+" | head -1) || apply_add=0
            apply_changed=$(grep -o "[0-9]\+ changed" apply_output.txt | grep -o "[0-9]\+" | head -1) || apply_changed=0
            apply_destroyed=$(grep -o "[0-9]\+ destroyed" apply_output.txt | grep -o "[0-9]\+" | head -1) || apply_destroyed=0
            
            # Use whichever count is higher
            resources_applied=$((created > apply_add ? created : apply_add))
            resources_changed=$((modified > apply_changed ? modified : apply_changed))
            resources_destroyed=$((destroyed > apply_destroyed ? destroyed : apply_destroyed))
            
            echo "resources_applied=$resources_applied" >> "$GITHUB_OUTPUT"
            echo "resources_changed=$resources_changed" >> "$GITHUB_OUTPUT"
            echo "resources_destroyed=$resources_destroyed" >> "$GITHUB_OUTPUT"
          else
            echo "resources_applied=0" >> "$GITHUB_OUTPUT"
            echo "resources_changed=0" >> "$GITHUB_OUTPUT"
            echo "resources_destroyed=0" >> "$GITHUB_OUTPUT"
          fi
          
          # Determine status based on apply result
          apply_status="unknown"
          
          if [ "$final_exit_code" -eq 0 ]; then
            if [ -f "apply_output.txt" ] && (grep -q "Apply complete!" apply_output.txt || grep -q "No changes" apply_output.txt); then
              apply_status="success"
              echo "✅ Scheduling apply completed successfully"
            else
              apply_status="completed_with_warnings"
              echo "⚠️ Scheduling apply completed but with potential warnings"
            fi
          else
            apply_status="failed"
            echo "❌ Scheduling apply failed: Exit code $final_exit_code"
            
            # Enhanced error capture for better debugging
            echo "=== Capturing Scheduling error details for debugging ==="
            if [ -f "apply_output.txt" ] && [ -s "apply_output.txt" ]; then
              echo "Using apply output for error details"
              tail -50 apply_output.txt > apply_errors.txt
            elif [ -f "plan_errors.txt" ] && [ -s "plan_errors.txt" ]; then
              echo "Using plan errors for error details"
              cp plan_errors.txt apply_errors.txt
            elif [ -f "plan_output.txt" ] && [ -s "plan_output.txt" ]; then
              echo "Using plan output for error details"
              tail -50 plan_output.txt > apply_errors.txt
            elif [ -f "init_output.txt" ] && [ -s "init_output.txt" ]; then
              echo "Using init output for error details"
              tail -50 init_output.txt > apply_errors.txt
            else
              echo "No detailed error logs available" > apply_errors.txt
            fi
            
            # Check for dependency issues and add helpful context
            if [ -f "apply_errors.txt" ]; then
              if grep -q "no matching EC2 Security Group found" apply_errors.txt; then
                echo "Dependency Issue: Security Group not found" >> apply_errors.txt
                echo "Possible cause: apply-keeping job may not have completed successfully" >> apply_errors.txt
              fi
              if grep -q "couldn't find resource.*IAM Role" apply_errors.txt; then
                echo "Dependency Issue: IAM Role not found" >> apply_errors.txt
                echo "Possible cause: apply-keeping job may not have created required IAM resources" >> apply_errors.txt
              fi
              if grep -q "empty result.*SNS Topic" apply_errors.txt; then
                echo "Dependency Issue: SNS Topic not found" >> apply_errors.txt
                echo "Possible cause: apply-keeping job may not have created SNS resources" >> apply_errors.txt
              fi
            fi
          fi
          
          # Set the status output
          echo "status=$apply_status" >> "$GITHUB_OUTPUT"
        env:
          TF_VAR_aws_account_id: ${{ env.AWS_ACCOUNT_ID }}

      - name: Upload Scheduling Apply Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: terragrunt-apply-scheduling
          path: |
            terragrunt/environments/scheduling/apply_output.txt
            terragrunt/environments/scheduling/plan_output.txt
            terragrunt/environments/scheduling/init_output.txt
            terragrunt/environments/scheduling/apply_errors.txt
            terragrunt/environments/scheduling/plan_errors.txt
          retention-days: 30

      - name: Debug Scheduling Apply Results  
        if: always() && steps.check-env.outputs.exists == 'true'
        working-directory: terragrunt/environments/scheduling
        run: |
          echo "=== Debugging Apply Results for Scheduling ==="
          echo "Checking for scheduling output files..."
          
          if [ -f "apply_output.txt" ]; then
            echo "✅ apply_output.txt exists, size: $(wc -c < apply_output.txt) bytes"
            echo "=== Full Scheduling Apply Output ==="
            cat apply_output.txt
            echo "=== End Full Scheduling Apply Output ==="
          else
            echo "❌ apply_output.txt not found"
          fi
          
          if [ -f "plan_output.txt" ]; then
            echo "✅ plan_output.txt exists, size: $(wc -c < plan_output.txt) bytes"
            echo "=== Scheduling Plan Output ==="
            cat plan_output.txt
            echo "=== End Scheduling Plan Output ==="
          else
            echo "❌ plan_output.txt not found"
          fi
          
          if [ -f "plan_errors.txt" ]; then
            echo "✅ plan_errors.txt exists, size: $(wc -c < plan_errors.txt) bytes"
            echo "=== Scheduling Plan Errors ==="
            cat plan_errors.txt
            echo "=== End Scheduling Plan Errors ==="
          else
            echo "❌ plan_errors.txt not found"
          fi
          
          if [ -f "apply_errors.txt" ]; then
            echo "✅ apply_errors.txt exists, size: $(wc -c < apply_errors.txt) bytes"
            if [ -s "apply_errors.txt" ]; then
              echo "=== Scheduling Apply Errors Content ==="
              cat apply_errors.txt
              echo "=== End Scheduling Apply Errors ==="
            fi
          else
            echo "❌ apply_errors.txt not found"
          fi

      - name: Slack Notification on Success
        if: success()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: https://hooks.slack.com/services/${{ secrets.WEBHOOK_PATH }}
          SLACK_USERNAME: TerragruntBot
          SLACK_TITLE: "Terragrunt Apply Success - scheduling"
          SLACK_COLOR: good
          SLACK_MESSAGE: "scheduling environment applied successfully 🚀"

      - name: Slack Notification on Failure
        if: failure()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: https://hooks.slack.com/services/${{ secrets.WEBHOOK_PATH }}
          SLACK_USERNAME: TerragruntBot
          SLACK_TITLE: "Terragrunt Apply Failed - scheduling"
          SLACK_COLOR: danger
          SLACK_MESSAGE: "scheduling environment apply failed 😢"

  comment-apply-results:
    name: Comment Apply Results
    runs-on: ubuntu-latest
    needs: [check-changes, debug-conditions, apply-keeping, apply-scheduling]
    if: |
      always() && 
      needs.check-changes.outputs.pr_number != '' && 
      needs.check-changes.outputs.pr_number != null && 
      (
        needs.apply-keeping.result == 'success' || 
        needs.apply-scheduling.result == 'success' || 
        needs.apply-keeping.result == 'failure' || 
        needs.apply-scheduling.result == 'failure' ||
        needs.apply-keeping.outputs.apply_status == 'plan_failed' ||
        needs.apply-scheduling.outputs.apply_status == 'plan_failed' ||
        needs.apply-keeping.outputs.apply_status == 'init_failed' ||
        needs.apply-scheduling.outputs.apply_status == 'init_failed'
      )
    steps:
      - name: Debug Comment Job Conditions
        run: |
          echo "=== Debugging comment-apply-results job conditions ==="
          echo "PR number: '${{ needs.check-changes.outputs.pr_number }}'"
          echo "PR number != '': ${{ needs.check-changes.outputs.pr_number != '' }}"
          echo "PR number != null: ${{ needs.check-changes.outputs.pr_number != null }}"
          
          echo "Job results:"
          echo "  apply-keeping.result: '${{ needs.apply-keeping.result }}'"
          echo "  apply-scheduling.result: '${{ needs.apply-scheduling.result }}'"
          
          echo "Job status outputs:"
          echo "  apply-keeping.outputs.apply_status: '${{ needs.apply-keeping.outputs.apply_status }}'"
          echo "  apply-scheduling.outputs.apply_status: '${{ needs.apply-scheduling.outputs.apply_status }}'"
          
          echo "Individual condition checks:"
          echo "  apply-keeping.result == 'success': ${{ needs.apply-keeping.result == 'success' }}"
          echo "  apply-scheduling.result == 'success': ${{ needs.apply-scheduling.result == 'success' }}"
          echo "  apply-keeping.result == 'failure': ${{ needs.apply-keeping.result == 'failure' }}"
          echo "  apply-scheduling.result == 'failure': ${{ needs.apply-scheduling.result == 'failure' }}"
          echo "  apply-keeping.outputs.apply_status == 'plan_failed': ${{ needs.apply-keeping.outputs.apply_status == 'plan_failed' }}"
          echo "  apply-scheduling.outputs.apply_status == 'plan_failed': ${{ needs.apply-scheduling.outputs.apply_status == 'plan_failed' }}"
          echo "  apply-keeping.outputs.apply_status == 'init_failed': ${{ needs.apply-keeping.outputs.apply_status == 'init_failed' }}"
          echo "  apply-scheduling.outputs.apply_status == 'init_failed': ${{ needs.apply-scheduling.outputs.apply_status == 'init_failed' }}"
          
      - name: Checkout
        uses: actions/checkout@v4

      - name: Comment Apply Results
        uses: actions/github-script@v7
        with:
          script: |
            const commentHandler = require('./scripts/github-actions/comment-handler.js');
            
            // Process both environments in sequence
            const environments = [
              {
                name: 'keeping',
                status: '${{ needs.apply-keeping.outputs.apply_status }}',
                wasExecuted: '${{ needs.apply-keeping.result }}' !== 'skipped',
                resourcesApplied: '${{ needs.apply-keeping.outputs.resources_applied }}' || '0',
                resourcesChanged: '${{ needs.apply-keeping.outputs.resources_changed }}' || '0',
                resourcesDestroyed: '${{ needs.apply-keeping.outputs.resources_destroyed }}' || '0'
              },
              {
                name: 'scheduling', 
                status: '${{ needs.apply-scheduling.outputs.apply_status }}',
                wasExecuted: '${{ needs.apply-scheduling.result }}' !== 'skipped',
                resourcesApplied: '${{ needs.apply-scheduling.outputs.resources_applied }}' || '0',
                resourcesChanged: '${{ needs.apply-scheduling.outputs.resources_changed }}' || '0',
                resourcesDestroyed: '${{ needs.apply-scheduling.outputs.resources_destroyed }}' || '0'
              }
            ];
            
            // Get PR number and validate
            const prNumber = '${{ needs.check-changes.outputs.pr_number }}';
            console.log('PR Number from previous step:', prNumber);
            console.log('Type of PR number:', typeof prNumber);
            console.log('PR number length:', prNumber ? prNumber.length : 'undefined');
            console.log('PR number trimmed:', prNumber ? prNumber.trim() : 'undefined');
            
            // Convert to number with validation
            const prNumberInt = parseInt(prNumber ? prNumber.trim() : '', 10);
            console.log('Parsed PR number (parseInt result):', prNumberInt);
            console.log('Is parsed number valid:', !isNaN(prNumberInt) && prNumberInt > 0);
            
            if (prNumber && prNumber.trim() !== '' && prNumber !== 'null' && !isNaN(prNumberInt) && prNumberInt > 0) {
              console.log('✅ Using PR number for comments:', prNumberInt);
              
              for (const env of environments) {
                // Skip if the job was skipped (e.g., keeping failed so scheduling was skipped)
                if (!env.wasExecuted) {
                  console.log(`⏭️ Skipping ${env.name} environment - job was not executed`);
                  continue;
                }
                
                console.log(`Processing ${env.name} environment apply results...`);
                
                const inputs = {
                  commentType: 'terragrunt-apply',
                  environment: env.name,
                  status: env.status || 'unknown',
                  // Use apply results from job outputs instead of artifacts
                  resourcesApplied: env.resourcesApplied,
                  resourcesChanged: env.resourcesChanged,
                  resourcesDestroyed: env.resourcesDestroyed,
                  // Flag to indicate this is from apply workflow
                  isApplyWorkflow: true,
                  // Override PR number for API calls
                  prNumber: prNumberInt
                };
                
                try {
                  await commentHandler(github, context, inputs);
                  console.log(`✅ Successfully processed ${env.name} environment apply results`);
                } catch (error) {
                  console.error(`❌ Error processing ${env.name} environment apply results:`, error);
                  console.error('Error details:', {
                    message: error.message,
                    status: error.status,
                    response: error.response?.data
                  });
                  // Continue processing other environments even if one fails
                }
              }
            } else {
              console.log('❌ No valid PR number found, skipping comment operations');
              console.log('Available PR number value:', prNumber);
              console.log('Type of PR number:', typeof prNumber);
              console.log('Parsed number result:', prNumberInt);
              console.log('Is valid number check result:', !isNaN(prNumberInt) && prNumberInt > 0);
              return;
            }
